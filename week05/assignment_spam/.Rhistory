setwd("~/Documents/Pessoal/course_challenges/week05/assignment_wikipedia")
wiki = read.csv("wiki.csv", stringsAsFactors=FALSE)
str(wiki)
table(wiki$Vandal)
library(tm)
corpusAdded = Corpus(VectorSource(wiki$Added))
corpusAdded[[1]]
corpusAdded <- tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded[[1]]
corpusAdded <- tm_map(corpusAdded, stemDocument)
corpusAdded[[1]]
dtmAdded = DocumentTermMatrix(corpusAdded)
length(stopwords("english"))
dtm
dtmAdded
dtmAdded = removeSparseTerms(dtmAdded, 0.97)
dtmAdded
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded = DocumentTermMatrix(corpusAdded)
length(stopwords("english"))
dtmAdded
sparseAdded = removeSparseTerms(dtmAdded, 0.997)
dtmAdded
sparseAdded
wordsAdded = as.data.frame(as.matrix(sparseAdded))
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
corpusRemoved = Corpus(VectorSource(wiki$Removed))
corpusRemoved <- tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved <- tm_map(corpusRemoved, stemDocument)
dtmRemoved = DocumentTermMatrix(corpusRemoved)
sparseRemoved = removeSparseTerms(dtmRemoved, 0.997)
sparseRemoved
wordsRemoved = as.data.frame(as.matrix(sparseRemoved))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
str(wordsRemoved)
?cbind
View(wordsAdded)
cbind(wordsAdded,wordsRemoved)
wikiWords = cbind(wordsAdded,wordsRemoved)
wikiWords$Vandal = wiki$Vandal
str(wikiWords)
table(wikiWords$Vandal)
2061 / (2061+1815)
library(rpart)
library(rpart.plot)
library(caTools)
spl = sample.split(wikiWords$Vandal, 0.7)
train = subset(wikiWords, spl == TRUE)
test = subset(wikiWords, spl == FALSE)
CART = rpart(Vandal~., data=train, method="class")
pred = predict(CART, newdata=test)
table(test$Vandal, pred >= 0.5)
table(test$Vandal, pred[,2] >= 0.5)
(618+8)/(618+8+537)
prp(CART)
wikiWords2 = wikiWords
wikiWords2$HTTP = ifelse(grepl("http",wiki$Added,fixed=TRUE), 1, 0)
table(wikiWords2$HTTP)
wikiTrain2 = subset(wikiWords2, spl==TRUE)
wikiTest2 = subset(wikiWords2, spl==FALSE)
CART2 = rpart(Vandal~., data=wikiTrain2, method="class")
pred2 = predict(CART2, newdata=wikiTest2)
table(wikiTest2$Vandal, pred2[,2] >= 0.5)
(607+60)/(607+60+11+485)
wikiWords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))
wikiWords2$NumWordsRemoved = rowSums(as.matrix(dtmRemoved))
summary(wikiWords2$NumWordsAdded)
wikiTrain3 = subset(wikiWords2, spl==TRUE)
wikiTest3 = subset(wikiWords2, spl==FALSE)
CART3 = rpart(Vandal~., data=wikiTrain3, method="class")
pred3 = predict(CART3, newdata=wikiTest3)
table(wikiTest3$Vandal, pred3[,2] >= 0.5)
(499+250)/(499+250+119+295)
summary(wikiWords2$NumWordsAdded)
set.seed(123)
split = sample.split(wikiWords$Vandal, SplitRatio = 0.7)
wikiTrain3 = subset(wikiWords2, split==TRUE)
wikiTest3 = subset(wikiWords2, split==FALSE)
CART3 = rpart(Vandal~., data=wikiTrain3, method="class")
pred3 = predict(CART3, newdata=wikiTest3)
table(wikiTest3$Vandal, pred3[,2] >= 0.5)
(514+248)/(514+248+104+297)
wikiWords3 = wikiWords2
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin
set.seed(123)
split = sample.split(wikiWords$Vandal, SplitRatio = 0.7)
wikiTrain4 = subset(wikiWords3, split==TRUE)
wikiTest4 = subset(wikiWords3, split==FALSE)
CART4 = rpart(Vandal~., data=wikiTrain4, method="class")
pred4 = predict(CART4, newdata=wikiTest4)
table(wikiTest4$Vandal, pred4[,2] >= 0.5)
(595+241)/(595+241+23+304)
prp(CART4)
setwd("~/Documents/Pessoal/course_challenges/week05/assignment_clinical")
trials = csv.read("clinical_trial.csv",stringsAsFactors = FALSE)
trials = read.csv("clinical_trial.csv",stringsAsFactors = FALSE)
summary(trials)
str(trials)
?len
?length
length("adfgadfg")
strn("adfgadfg")
nchar("adfgadfg")
sort(table(nchar(trials$Abstract))
sort(table(nchar(trials$Abstract)))
sort(nchar(trials$Abstract))
summary(trials)
nchar(trials$Abstract)
nchar(trials$abstract)
sort(nchar(trials$abstract))
table(nchar(trials$abstract)==0)
?which.min
trials$title[which.min(nchar(trials$title))]
corpusTitle = Corpus(VectorSource(trials$title))
corpusTitle <- tm_map(corpusTitle, tolower)
corpusTitle <- tm_map(corpusTitle, removePunctuation)
corpusTitle <- tm_map(corpusTitle, removeWords, stopwords("english"))
corpusTitle <- tm_map(corpusTitle, stemDocument)
dtmTitle = DocumentTermMatrix(corpusTitle)
dtmTitle = removeSparseTerms(dtmTitle, 0.95)
dfTitle = as.data.frame(as.matrix(dtmTitle))
corpusAbstract = Corpus(VectorSource(trials$abstract))
corpusAbstract <- tm_map(corpusAbstract, tolower)
corpusAbstract <- tm_map(corpusAbstract, removePunctuation)
corpusAbstract <- tm_map(corpusAbstract, removeWords, stopwords("english"))
corpusAbstract <- tm_map(corpusAbstract, stemDocument)
dtmAbstract = DocumentTermMatrix(corpusAbstract)
dtmAbstract = removeSparseTerms(dtmAbstract, 0.95)
dfAbstract = as.data.frame(as.matrix(dtmAbstract))
dtmTitle
dtmAbstract
colSums(dtmAbstract)
colSums(dfAbstract)
sort(colSums(dfAbstract))
?paste0
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
dtmTitle
corpusTitle = Corpus(VectorSource(trials$title))
corpusTitle <- tm_map(corpusTitle, tolower)
corpusTitle <- tm_map(corpusTitle, removePunctuation)
corpusTitle <- tm_map(corpusTitle, removeWords, stopwords("english"))
corpusTitle <- tm_map(corpusTitle, stemDocument)
dtmTitle = DocumentTermMatrix(corpusTitle)
dtmTitle = removeSparseTerms(dtmTitle, 0.95)
dfTitle = as.data.frame(as.matrix(dtmTitle))
###### corpusAbstract
corpusAbstract = Corpus(VectorSource(trials$abstract))
corpusAbstract <- tm_map(corpusAbstract, tolower)
corpusAbstract <- tm_map(corpusAbstract, removePunctuation)
corpusAbstract <- tm_map(corpusAbstract, removeWords, stopwords("english"))
corpusAbstract <- tm_map(corpusAbstract, stemDocument)
dtmAbstract = DocumentTermMatrix(corpusAbstract)
dtmAbstract = removeSparseTerms(dtmAbstract, 0.95)
dfAbstract = as.data.frame(as.matrix(dtmAbstract))
dtmAbstract = as.data.frame(as.matrix(dtmAbstract))
dtmTitle = as.data.frame(as.matrix(dtmTitle))
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
dtmTitle
dtm = cbind(dtmTitle,dtmAbstract)
dtm$trial = trials$trial
str(dtm)
set.seed(144)
spl = sample.split(dtm$trial, 0.7)
train = subset(dtm, spl == TRUE)
test = subset(dtm, spl == FALSE)
table(train$trial)
730/(730+572)
CART = rpart(trial~., data=train, method="class")
pred = predict(CART, newdata=test)
table(test$trial, pred[,2] >= 0.5)
prp(CART)
pred = predict(CART, type="response")
pred = predict(CART, type="class")
sort(pred[,2])
sort(pred)
pred = predict(CART)
sort(pred)
table(pred[,2])
table(train$trial,pred[,2])
table(train$trial,pred[,2]>=0.5)
(631+441)/(631+441+99+131)
441/(441+131)
631/(631+99)
predTest = predict(CART,newdata=test,type="class")
predTest
table(test$trial,predTest)
(261+162)/(261+162+52+83)
library(ROCR)
predROCR = prediction(predTest, test$trial)
predROCR = prediction(predTest, test$trial)
predTest = predict(CART,newdata=test)
predROCR = prediction(predTest, test$trial)
predROCR = prediction(predTest[,2], test$trial)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
performance(predROCR, "auc")@y.values
predTest
performance(predROCR, "auc")@y.values
table(test$trial,predTest[,2]>=0.3)
table(test$trial,predTest[,2]>=0.2)
table(test$trial,predTest[,2]>=0.1)
table(test$trial,predTest[,2]>=0.7)
table(test$trial,predTest[,2]>=0.9)
table(test$trial,predTest[,2]>=0.8)
table(test$trial,predTest[,2]>=0.89)
table(test$trial,predTest[,2]>=0.86)
table(test$trial,predTest[,2]>=0.88)
table(test$trial,predTest[,2]>=0.87)
table(test$trial,predTest[,2]>=0.879)
table(test$trial,predTest[,2]>=0.873)
table(test$trial,predTest[,2]>=0.872)
table(test$trial,predTest[,2]>=0.871)
table(test$trial,predTest[,2]>=0.8719)
table(test$trial,predTest[,2]>=0.8715)
table(test$trial,predTest[,2]>=0.87153)
table(test$trial,predTest[,2]>=0.87158)
table(test$trial,predTest[,2]>=0.37158)
table(test$trial,predTest[,2]>=0.27158)
setwd("~/Documents/Pessoal/course_challenges/week05/assignment_spam")
emails = read.csv("emails.csv")
nrow(emails)
table(emails$spam)
emails$text[1]
emails$text[2]
max(now(emails$text))
max(nchar(emails$text))
emails = read.csv("emails.csv", stringsAsFactors=FALSE)
nrow(emails)
# 1.2 How many of the emails are spam
table(emails$spam)
# 1.3
emails$text[2]
#1.5
max(nchar(emails$text))
which.min(nchar(emails$text))
corpus = Corpus(VectorSource(emails$text))
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(colnames(emailsSparse))
sort(colSums(emailsSparse))
colSums(emailsSparse)
?colSums
emailsSparse$spam = emails$spam
colSums(emailsSparse)
match(colSums(emailsSparse),[,2]!="spam")
sort(colSums(emailsSparse-spam))
sort(colSums(emailsSparse-emailsSparse$spam))
colSums(emailsSparse-emailsSparse$spam)
colSums(emailsSparse,emailsSparse$spam==0)
colSums(emailsSparse,emailsSparse$spam==1)
table(emailsSparse)
match(emailsSparse,span==0)
match(emailsSparse,emailsSparse$span==0)
nrow(match(emailsSparse,emailsSparse$span==0))
emailsSparse$span
nrow(match(emailsSparse,emailsSparse$spam==0))
emailsSparse$spam
nrow(match(emailsSparse,emailsSparse$spam==0))
?filter
?match
nrow(match(emailsSparse$spam==0,emailsSparse))
match(emailsSparse$spam==0,emailsSparse)
match(emailsSparse$spam=0,emailsSparse)
?find
?filter
table(colSums(emailsSparse),emailsSparse$spam)
table(colSums(emailsSparse),emailsSparse$spam==1)
table(colSums(emailsSparse)>5000,emailsSparse$spam==1)
table(colSums(emailsSparse)>5000)
table(colSums(emailsSparse)>5000 && emailsSparse$spam==0)
sort(nchar(subset(emailsSparse, spam==0)))
sort(colnames(subset(emailsSparse, spam==0)))
sort(colSums(subset(emailsSparse, spam==0)))
table(sort(colSums(subset(emailsSparse, spam==0))) >=1000 )
table(sort(colSums(subset(emailsSparse, spam==1))) >=1000 )
sort(colSums(subset(emailsSparse, spam==1)))
emailsSparse$spam = as.factor(emailsSparse$spam)
set.seed(123)
set.seed(123)
split = sample.split(emailsSparse$spam, SplitRatio = 0.7)
train = subset(emailsSparse, split==TRUE)
test = subset(emailsSparse, split==FALSE)
source.with.encoding('~/Documents/Pessoal/course_challenges/week02/lectures_wine/Week2_WineRegression.R', encoding='UTF-8')
spamLog = glm(spam ~ . , data= train, family=binomial)
spamCART = rpart(spam~., data=train, method="class")
library(randomForest)
set.seed(123)
spamRF = randomForest(spam ~ ., data=train)
predLog = predict(spamLog)
predCART = predict(predCART)
predCART = predict(spamCART)
predRF = predict(spamRF,type="prob")
table(spamLog>0.00001)
sort(spamLog)
table(predLog>0.00001)
table(predLog>0.99999)
table(predLog<0.99999)
table(predLog >=0.00001 && predLog<=0.99999)
table(predLog >=0.00001 ,predLog<=0.99999)
table(predLog<0.00001)
summary(spamLog)
prp(spamCART)
table(train$spam,predLog<=0.5)
table(train$spam,predLog>=0.5)
(3052+954)/(3052+954+4)
library(ROCR)
predROCR = prediction(predLog[,2], test$spam)
predROCR = prediction(predLog, test$spam)
predROCR = prediction(predLog, train$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
performance(predROCR, "auc")@y.values
table(train$spam,predCART[,2]>=0.5)
(2885+894)/(2885+894+167+64)
predROCR = prediction(predCART, train$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
# Compute AUC
performance(predROCR, "auc")@y.values
predROCR = prediction(predCART[,2], train$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
# Compute AUC
performance(predROCR, "auc")@y.values
set.seed(123)
spamRF = randomForest(spam ~ ., data=train)
predRF = predict(spamRF,type="prob")
table(train$spam,predRF[,2]>=0.5)
(3013+914)/(3013+914+44+39)
predROCR = prediction(predRF[,2], train$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
performance(predROCR, "auc")@y.values
predLog = predict(spamLog,newdata=test)
predCART = predict(spamCART,newdata=test)
predRF = predict(spamRF,newdata=test,type="prob")
table(test$spam,predLog)
table(test$spam,predLog>=0.5)
(1258+376)/(1258+376+50+34)
predROCR = prediction(predLog, test$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
table(test$spam,predCART>=0.5)
table(test$spam,predCART[2]>=0.5)
table(test$spam,predCART[,2]>=0.5)
(1228+386)/(1228+386+80+24)
predROCR = prediction(predCART[,2], test$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
table(test$spam,predRF[,2]>=0.5)
(1290+386)/(1290+386+18+24)
predROCR = prediction(predRF[,2], test$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
wordCount = rowSums(as.matrix(dtm))
hist(wordCount)
hist(log(wordCount))
emailsSparse$logWordCount = log(wordCount)
boxplot(emailsSparse$logWordCount,emailsSparse$spam)
boxplot(emailsSparse$spam,emailsSparse$logWordCount)
boxplot(logWordCount~spam, data=emailsSparse)
set.seed(123)
split = sample.split(emailsSparse$spam, SplitRatio = 0.7)
train2 = subset(emailsSparse, split==TRUE)
test2 = subset(emailsSparse, split==FALSE)
spam2CART = rpart(spam~., data=train2)
prp(spam2CART)
set.seed(123)
spam2RF = randomForest(spam ~ ., data=train2)
pred2CART = predict(spam2CART,newdata=test)
pred2CART = predict(spam2CART,newdata=test2)
pred2RF = predict(spam2RF,newdata=test2,type="prob")
table(test2$spam,spam2CART[,2])
table(test2$spam,spam2CART)
pred2CART = predict(spam2CART,newdata=test2, method="class")
table(test2$spam,spam2CART)
table(test2$spam,spam2CART[,2])
table(test2$spam,pred2CART[,2])
table(test2$spam,pred2CART)
pred2CART = predict(spam2CART,newdata=test2)
table(test2$spam,pred2CART[,2])
table(test2$spam,pred2CART[,2]>=0.5)
(1214+384)/(1214+384+26+94)
predROCR = prediction(pred2RF[,2], test2$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
predROCR = prediction(pred2CART[,2], test2$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
table(test2$spam,pred2RF[,2]>=0.5)
(1296+383)/(1296+383+27+12)
predROCR = prediction(pred2RF[,2], test2$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
package("RTextTools")
library(RTextTools)
dtm2gram = create_matrix(as.character(corpus), ngramLength=2)
dtm2gram
spdtm2gram = removeSparseTerms(dtm2gram, 0.95)
spdtm2gram
emailsSparse2gram = s.data.frame(as.matrix(spdtm2gram))
colnames(emailsSparse2gram) = make.names(colnames(emailsSparse2gram))
emailsSparse2gram = as.data.frame(as.matrix(spdtm2gram))
colnames(emailsSparse2gram) = make.names(colnames(emailsSparse2gram))
emailsCombined = cbind(emailsSparse, emailsSparse2gram)
set.seed(123)
split = sample.split(emailsSparse$spam, SplitRatio = 0.7)
split = sample.split(emailsCombined$spam, SplitRatio = 0.7)
trainCombined = subset(emailsCombined, split==TRUE)
testCombined = subset(emailsCombined, split==FALSE)
spamCARTcombined = rpart(spam~., data=trainCombined)
spamRFcombined = randomForest(spam ~ ., data=trainCombined)
prp(spamCARTcombined,varlen=0)
prp(spamCARTcombined,varlen=0)
spamCARTcombined = rpart(spam~., data=trainCombined)
prp(spamCARTcombined,varlen=0)
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(colnames(emailsSparse))
emailsSparse$spam = emails$spam
emailsSparse$spam = as.factor(emailsSparse$spam)
spamCARTcombined
str(trainCombined)
colnames(trainCombined)
spamCARTcombined = rpart(spam~., data=trainCombined)
prp(spamCARTcombined,varlen=0)
set.seed(123)
spamCARTcombined = rpart(spam~., data=trainCombined)
prp(spamCARTcombined,varlen=0)
pred3CART = predict(spamCARTcombined,newdata=testCombined)
table(testCombined$spam,pred3CART[,2]>=0.5)
(1248+367)/(1248+367+60+43)
predROCR = prediction(pred3CART[,2], testCombined$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
pred3RF = predict(spamRFcombined,newdata=testCombined,type="prob")
table(testCombined$spam,pred3RF[,2]>=0.5)
(1297+389)/(1297+389+11+21)
predROCR = prediction(pred3RF[,2], testCombined$spam)
perfROCR = performance(predROCR, "tpr", "fpr")
performance(predROCR, "auc")@y.values
