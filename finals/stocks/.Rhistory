setwd("~/Documents/Pessoal/course_challenges/finals/elantra")
elantra = read.csv("elantra.csv")
str(elantr)
str(elantra)
train = subset(elantr,Year<=2012)
train = subset(elantra,Year<=2012)
test =  subset(elantra,Year>2012)
str(train)
model = lm(ElantraSales ~ Unemployment+CPI_all+CPI_energy +Queries,data=train )
summary(model)
model2 = lm(ElantraSales ~ Month+Unemployment+CPI_all+CPI_energy +Queries,data=train )
summary(model2)
setwd("~/Documents/Pessoal/course_challenges/finals/nytimes")
articles = read.csv("nytimes.csv",stringsAsFactors=FALSE)
str(articles)
table(artiles$word.count>=100)
table(articles$word.count>=100)
967/(967+6)
table(articles$type>=100)
table(articles$type)
cor(articles)
correlation(articles)
cor(articles$word.count)
cor(articles$word.count,articles$popular)
cor(nchar(articles$headline),articles$popular)
articles$popular =  as.factor(articles$popular)
articles$type =  as.factor(articles$type)
library(caTools)
set.seed(144)
split = sample.split(articles$popular, SplitRatio = 0.7)
train = subset(articles$popular, split==TRUE)
test = subset(articles$popular, split==FALSE)
logmodel = glm(popular ~ print+type+word.count,  data=train, family=binomial)
str(train)
set.seed(144)
split = sample.split(articles$popular, SplitRatio = 0.7)
train = subset(articles, split==TRUE)
test = subset(articles, split==FALSE)
logmodel = glm(popular ~ print+type+word.count,  data=train, family=binomial)
summary(logmodel)
-2.5075573 + (1*-0.8468333) + (682*0.0002600)
1/(1+(-2.5075573 + (1*-0.8468333) + (682*0.0002600) ) )
xxx = -2.5075573 + (1*-0.8468333) + (682*0.0002600)
e
e <- exp(1)
1/ ( 1+(e^(-xxx)  )
)
setwd("~/Documents/Pessoal/course_challenges/finals/elantra")
# Problem 1
elantra = read.csv("elantra.csv")
str(elantra)
train = subset(elantra,Year<=2012)
test =  subset(elantra,Year>2012)
str(train)
# Problem 2
model = lm(ElantraSales ~ Unemployment+CPI_all+CPI_energy +Queries,data=train )
summary(model)
# Problem 6
model2 = lm(ElantraSales ~ Month+Unemployment+CPI_all+CPI_energy +Queries,data=train )
summary(model2)
elantra$Month = as.factor(elantra$Month)
model2 = lm(ElantraSales ~ Month+Unemployment+CPI_all+CPI_energy +Queries,data=train )
summary(model2)
train = subset(elantra,Year<=2012)
test =  subset(elantra,Year>2012)
str(train)
model2 = lm(ElantraSales ~ Month+Unemployment+CPI_all+CPI_energy +Queries,data=train )
summary(model2)
# Problem 13
elantra2 = read.csv("elantra.csv")
str(elantra2)
cor(elantra2)
model2
summary(model2)
model2 = lm(ElantraSales ~ Month+Unemployment+CPI_all+CPI_energy ,data=train )
summary(model2)
pred = predict(model2, newdata= test)
summary(pred)
SSE = sum(  ( test$ElantraSales - pred )^2  )
SSE
mean(test$ElantraSales)
mean(train$ElantraSales)
mean(train$ElantraSales)
SST = sum( ( test$ElantraSales - mean(train$ElantraSales))^2 )
SST
rsquared = 1 - SSE/SST
rsquared
max(pred)
abs(-10)
max(abs( pred - test$ElantraSales ))
sort(abs( pred - test$ElantraSales ))
test[14]
test[14,]
test$maxdif = pred - test$ElantraSales
which.max(test$maxdif)
test[which.max(test$maxdif),]
articles = read.csv("nytimes.csv",stringsAsFactors=FALSE)
str(articles)
table(articles$type)
967/(967+6)
cor(nchar(articles$headline),articles$popular)
articles$popular =  as.factor(articles$popular)
articles$type =  as.factor(articles$type)
library(caTools)
set.seed(144)
split = sample.split(articles$popular, SplitRatio = 0.7)
train = subset(articles, split==TRUE)
test = subset(articles, split==FALSE)
logmodel = glm(popular ~ print+type+word.count,  data=train, family=binomial)
summary(logmodel)
print=1
type news
wordcount 682
1/(1+(-2.5075573 + (1*-0.8468333) + (682*0.0002600) ) )
e <- exp(1)
xxx = -2.5075573 + (1*-0.8468333) + (682*0.0002600)
1/ ( 1+(e^(-xxx)  )
)
setwd("~/Documents/Pessoal/course_challenges/finals/nytimes")
articles = read.csv("nytimes.csv",stringsAsFactors=FALSE)
str(articles)
table(articles$type)
967/(967+6)
cor(nchar(articles$headline),articles$popular)
articles$popular =  as.factor(articles$popular)
articles$type =  as.factor(articles$type)
library(caTools)
set.seed(144)
split = sample.split(articles$popular, SplitRatio = 0.7)
train = subset(articles, split==TRUE)
test = subset(articles, split==FALSE)
logmodel = glm(popular ~ print+type+word.count,  data=train, family=binomial)
summary(logmodel)
print=1
type news
wordcount 682
1/(1+(-2.5075573 + (1*-0.8468333) + (682*0.0002600) ) )
e <- exp(1)
xxx = -2.5075573 + (1*-0.8468333) + (682*0.0002600)
1/ ( 1+(e^(-xxx)  ) )
articles = read.csv("nytimes.csv",stringsAsFactors=FALSE)
str(articles)
table(articles$type)
967/(967+6)
cor(nchar(articles$headline),articles$popular)
articles$popular =  as.factor(articles$popular)
articles$type =  as.factor(articles$type)
library(caTools)
set.seed(144)
split = sample.split(articles$popular, SplitRatio = 0.7)
train = subset(articles, split==TRUE)
test = subset(articles, split==FALSE)
logmodel = glm(popular ~ print+type+word.count,  data=train, family=binomial)
summary(logmodel)
1/(1+(-2.5075573 + (1*-0.8468333) + (682*0.0002600) ) )
e <- exp(1)
xxx = -2.5075573 + (1*-0.8468333) + (682*0.0002600)
1/ ( 1+(e^(-xxx)  ) )
baseline = table(train$popular)
baseline
baseline = 608/(608 + 74)
baseline
source('~/.active-rstudio-document')
pred = predict(logmodel,newData=test, type="response")
table(pred>=0.5)
table(train$popular,pred>=0.5)
table(pred>=0.5)
table(train$popular)
table(pred>=0.5)
setwd("~/Documents/Pessoal/course_challenges/finals/stocks")
stocks = read.csv("stocks.csv")
stocks = read.csv("nasdaq_returns.csv")
str(stocks)
table(stocks$symbol)
table(stocks$stock_symbol)
count(table(stocks$stock_symbol))
nrow(table(stocks$stock_symbol))
table(stocks$industry)
